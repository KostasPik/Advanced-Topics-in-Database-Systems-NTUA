{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf784cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>3690</td><td>application_1732639283265_3636</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3636/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-178.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3636_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, year, count, when, desc, sum, to_timestamp, row_number, regexp_replace, expr, asc\n",
    "from pyspark.sql.types import DecimalType\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e918faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME performance: 7.735968351364136\n",
      "DATAFRAME results: [Row(AGE GROUP='Adults', count=121093), Row(AGE GROUP='Young adults', count=33605), Row(AGE GROUP='Children', count=10830), Row(AGE GROUP='Elderly', count=5985), Row(AGE GROUP='Unknown', count=5098)]"
     ]
    }
   ],
   "source": [
    "### QUERY 1\n",
    "APP_NAME = \"Crime Victime Age Analysis\"\n",
    "SPARK_EXECUTORS = 4\n",
    "spark = SparkSession.builder.appName(APP_NAME).config(\"spark.executor.instances\", SPARK_EXECUTORS).getOrCreate()\n",
    "\n",
    "# crime data\n",
    "d1 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\",\n",
    "    header=True, inferSchema=True)\n",
    "d2 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",\n",
    "    header=True, inferSchema=True)\n",
    "crime_data = d1.union(d2)\n",
    "\n",
    "# DATAFRAME API BEGIN #\n",
    "start = time.time()\n",
    "filtered_df = crime_data.filter(crime_data[\"Crm Cd Desc\"].contains(\"AGGRAVATED ASSAULT\")) #get only aggravated assault\n",
    "grouped_df = filtered_df.withColumn(\"AGE GROUP\", when(filtered_df['Vict Age'] <= 0, \"Unknown\").when(filtered_df['Vict Age'] < 18, \"Children\").when(filtered_df[\"Vict Age\"] <= 24, \"Young adults\")\n",
    "                              .when(filtered_df['Vict Age'] <= 64, \"Adults\").when(filtered_df['Vict Age'] > 64, \"Elderly\"))\n",
    "categories_df = grouped_df.groupBy(\"AGE GROUP\").count().orderBy(desc('count')).collect() #group rows based on the age group assigned and count them\n",
    "end = time.time()\n",
    "dataframe_time = end-start\n",
    "print(\"DATAFRAME performance:\", end-start)\n",
    "print(\"DATAFRAME results:\", categories_df)\n",
    "# DATAFRAME API END #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781d50b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD performance: 16.28496217727661\n",
      "RDD results: [('Adults', 121093), ('Young adults', 33605), ('Children', 10830), ('Elderly', 5985), ('Unknown', 5098)]"
     ]
    }
   ],
   "source": [
    "# crime data\n",
    "d1 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\",\n",
    "    header=True, inferSchema=True)\n",
    "d2 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",\n",
    "    header=True, inferSchema=True)\n",
    "crime_data = d1.union(d2)\n",
    "\n",
    "def get_category_by_age(age):\n",
    "    if age is None:\n",
    "        return \"NULL\"\n",
    "    age = int(age)\n",
    "    category = None\n",
    "    if age <= 0:\n",
    "        category = 'Unknown'\n",
    "    elif age < 18:\n",
    "        category = \"Children\"\n",
    "    elif age <= 24:\n",
    "        category = \"Young adults\"\n",
    "    elif age <= 64:\n",
    "        category = \"Adults\"\n",
    "    else:\n",
    "        category = \"Elderly\"\n",
    "    return category\n",
    "\n",
    "# RDD API BEGIN #\n",
    "start = time.time()\n",
    "crime_rdd = crime_data.rdd # convert dataframe to rdd\n",
    "filtered_rdd = crime_rdd.filter(lambda row: \"AGGRAVATED ASSAULT\" in row[\"Crm Cd Desc\"])\n",
    "grouped_rdd = filtered_rdd.map(lambda row: (get_category_by_age(row[\"Vict Age\"]), 1))\n",
    "categories_rdd = grouped_rdd.reduceByKey(lambda x,y: x+y).sortBy(lambda tup: -tup[1]).collect()\n",
    "end = time.time()\n",
    "rdd_time = end - start\n",
    "print(\"RDD performance:\", end - start)\n",
    "print(\"RDD results:\", categories_rdd)\n",
    "# RDD API END #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca503d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Speedup: 2.1050967943017724"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe Speedup:\", rdd_time/dataframe_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
